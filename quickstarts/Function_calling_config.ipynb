{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDS9Xcj_8k-T"
      },
      "source": [
        "# Gemini API: Function calling config\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb\"><img src=\"https://github.com/google-gemini/cookbook/blob/main/images/colab_logo_32px.png?raw=1\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e41a2ce62eb"
      },
      "source": [
        "Specifying a `function_calling_config` allows you to control how the Gemini API acts when `tools` have been specified. For example, you can choose to only allow free-text output (disabling function calling), force it to choose from a subset of the functions provided in `tools`, or let it act automatically.\n",
        "\n",
        "This guide assumes you are already familiar with function calling. For an introduction, check out the [docs](https://ai.google.dev/docs/function_calling)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "m4DhA4907Asz"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU-mY9hi8pQh"
      },
      "source": [
        "To run the following cell, your API key must be stored in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/gemini-api-cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wp3W4Pdf8rBO"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJqil-VL8ug-"
      },
      "source": [
        "## Set up a model with tools\n",
        "\n",
        "This example uses 3 functions that control a simple hypothetical lighting system. Using these functions requires them to be called in a specific order. For example, you must turn the light system on before you can change color.\n",
        "\n",
        "While you can pass these directly to the model and let it try to call them correctly, specifying the `function_calling_config` gives you precise control over the functions that are available to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gLS26n7A9l9B"
      },
      "outputs": [],
      "source": [
        "def enable_lights():\n",
        "    \"\"\"Turn on the lighting system.\"\"\"\n",
        "    print(\"LIGHTBOT: Lights enabled.\")\n",
        "\n",
        "\n",
        "def set_light_color(rgb_hex: str):\n",
        "    \"\"\"Set the light color. Lights must be enabled for this to work.\"\"\"\n",
        "    print(f\"LIGHTBOT: Lights set to {rgb_hex}.\")\n",
        "\n",
        "\n",
        "def stop_lights():\n",
        "    \"\"\"Stop flashing lights.\"\"\"\n",
        "    print(\"LIGHTBOT: Lights turned off.\")\n",
        "\n",
        "\n",
        "light_controls = [enable_lights, set_light_color, stop_lights]\n",
        "instruction = \"You are a helpful lighting system bot. You can turn lights on and off, and you can set the color. Do not perform any other tasks.\"\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    \"models/gemini-1.5-pro\", tools=light_controls, system_instruction=instruction\n",
        ")\n",
        "\n",
        "chat = model.start_chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqROCznFCj_Y"
      },
      "source": [
        "Create a helper function for setting `function_calling_config` on `tool_config`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_QgLFPL4Chon"
      },
      "outputs": [],
      "source": [
        "from google.generativeai.types import content_types\n",
        "from collections.abc import Iterable\n",
        "\n",
        "\n",
        "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
        "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
        "    return content_types.to_tool_config(\n",
        "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofMEuh_MFdMf"
      },
      "source": [
        "## Text-only mode: `NONE`\n",
        "\n",
        "If you have provided the model with tools, but do not want to use those tools for the current conversational turn, then specify `NONE` as the mode. `NONE` tells the model not to make any function calls, and will behave as though none have been provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6ZlIFwXqGA09",
        "outputId": "705e1ba0-6566-4c7a-f55b-299751d2bf7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can turn lights on and off, and I can set the color of the lights.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tool_config = tool_config_from_mode(\"none\")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Hello light-bot, what can you do?\", tool_config=tool_config\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uux063sjHZ_Z"
      },
      "source": [
        "## Automatic mode: `AUTO`\n",
        "\n",
        "To allow the model to decide whether to respond in text or call specific functions, you can specify `AUTO` as the mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vwO9dUjvHoT8",
        "outputId": "ccd93f2f-823c-43cf-9fc6-5232dc7e4ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"enable_lights\"\n",
            "  args {\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tool_config = tool_config_from_mode(\"auto\")\n",
        "\n",
        "response = chat.send_message(\"Light this place up!\", tool_config=tool_config)\n",
        "print(response.parts[0])\n",
        "chat.rewind();  # You are not actually calling the function, so remove this from the history."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHhaO-P9CBPb"
      },
      "source": [
        "## Function-calling mode: `ANY`\n",
        "\n",
        "Setting the mode to `ANY` will force the model to make a function call. By setting `allowed_function_names`, the model will only choose from those functions. If it is not set, all of the functions in `tools` are candidates for function calling.\n",
        "\n",
        "In this example system, if the lights are already on, then the user can change color or turn the lights off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GQpz94zrCNJF",
        "outputId": "ce4fcc6f-a829-461e-fe8e-1d078ca1e22c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"set_light_color\"\n",
            "  args {\n",
            "    fields {\n",
            "      key: \"rgb_hex\"\n",
            "      value {\n",
            "        string_value: \"FF00FF\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "available_fns = [\"set_light_color\", \"stop_lights\"]\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "response = chat.send_message(\"Make this place PURPLE!\", tool_config=tool_config)\n",
        "print(response.parts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cGrRy-uJ7-J"
      },
      "source": [
        "## Automatic function calling\n",
        "\n",
        "`tool_config` works when enabling automatic function calling too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hx7aIX8OXvi6",
        "outputId": "41965e7c-a0ff-4b81-a07b-d875d2e33c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIGHTBOT: Lights enabled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"Let there be light!\\n\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"avg_logprobs\": -0.0561762402455012\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 169,\n",
              "        \"candidates_token_count\": 6,\n",
              "        \"total_token_count\": 175\n",
              "      },\n",
              "      \"model_version\": \"gemini-1.5-pro-002\"\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "available_fns = [\"enable_lights\"]\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "auto_chat.send_message(\"It's awful dark in here...\", tool_config=tool_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz8McBZfXg0N"
      },
      "source": [
        "## Further reading\n",
        "\n",
        "Check out the function calling [quickstart](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb) for an introduction to function calling. You can find another fun function calling example [here](https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb) using curl.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate a list of dictionary with 10 sample and key would be Roll Number, name, father, course, address\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_student_data(num_students=10):\n",
        "    students = []\n",
        "    for i in range(num_students):\n",
        "        student = {\n",
        "            \"Roll Number\": i + 1,\n",
        "            \"name\": f\"Student {i+1}\",\n",
        "            \"father\": f\"Father {i+1}\",\n",
        "            \"course\": random.choice([\"Computer Science\", \"Physics\", \"Mathematics\", \"Engineering\"]),\n",
        "            \"address\": f\"Address {i+1}\"\n",
        "        }\n",
        "        students.append(student)\n",
        "    return students\n",
        "\n",
        "student_data = generate_student_data()\n",
        "student_data"
      ],
      "metadata": {
        "id": "pSGEMpttibLW",
        "outputId": "045493e2-253d-420b-c909-845e968d9c40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Roll Number': 1,\n",
              "  'name': 'Student 1',\n",
              "  'father': 'Father 1',\n",
              "  'course': 'Computer Science',\n",
              "  'address': 'Address 1'},\n",
              " {'Roll Number': 2,\n",
              "  'name': 'Student 2',\n",
              "  'father': 'Father 2',\n",
              "  'course': 'Engineering',\n",
              "  'address': 'Address 2'},\n",
              " {'Roll Number': 3,\n",
              "  'name': 'Student 3',\n",
              "  'father': 'Father 3',\n",
              "  'course': 'Physics',\n",
              "  'address': 'Address 3'},\n",
              " {'Roll Number': 4,\n",
              "  'name': 'Student 4',\n",
              "  'father': 'Father 4',\n",
              "  'course': 'Physics',\n",
              "  'address': 'Address 4'},\n",
              " {'Roll Number': 5,\n",
              "  'name': 'Student 5',\n",
              "  'father': 'Father 5',\n",
              "  'course': 'Mathematics',\n",
              "  'address': 'Address 5'},\n",
              " {'Roll Number': 6,\n",
              "  'name': 'Student 6',\n",
              "  'father': 'Father 6',\n",
              "  'course': 'Physics',\n",
              "  'address': 'Address 6'},\n",
              " {'Roll Number': 7,\n",
              "  'name': 'Student 7',\n",
              "  'father': 'Father 7',\n",
              "  'course': 'Computer Science',\n",
              "  'address': 'Address 7'},\n",
              " {'Roll Number': 8,\n",
              "  'name': 'Student 8',\n",
              "  'father': 'Father 8',\n",
              "  'course': 'Engineering',\n",
              "  'address': 'Address 8'},\n",
              " {'Roll Number': 9,\n",
              "  'name': 'Student 9',\n",
              "  'father': 'Father 9',\n",
              "  'course': 'Computer Science',\n",
              "  'address': 'Address 9'},\n",
              " {'Roll Number': 10,\n",
              "  'name': 'Student 10',\n",
              "  'father': 'Father 10',\n",
              "  'course': 'Physics',\n",
              "  'address': 'Address 10'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Instruction=\"you have to generate student data from student_data when I will ask you and you have to generate data with roll I will give you roll and you have to generate data that specific student don't perform other tasks \"\n",
        "model = genai.GenerativeModel(\n",
        "    \"models/gemini-1.5-pro\",\n",
        "    system_instruction=Instruction\n",
        "  )\n",
        "chat=model.start_chat()\n",
        "\n",
        "response = chat.send_message(f\"tell me  the roll number 5 only address: {student_data}\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "wGDDU5IrlGIY",
        "outputId": "dcfde4d5-3899-40a9-9db1-0335650a44e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Address 5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Piaic_Student=[{\"name\":\"abuzar\",\n",
        "                \"father\":\"irshad\",\n",
        "                \"roll_number\":18,\n",
        "                \"address\":\"larkana\"\n",
        "                },\n",
        "               {\"name\":\"manzar\",\n",
        "                \"father\":\"irshad\",\n",
        "                \"roll_number\":16,\n",
        "                \"address\":\"ratodero\"},\n",
        "               {\"name\":\"feroz\",\n",
        "                \"father\":\"irshad\",\n",
        "                \"roll_number\":14,\n",
        "                \"address\":\"fatehpur\"}\n",
        "]\n",
        "student_info=Piaic_Student\n",
        "student_info"
      ],
      "metadata": {
        "id": "xd52YTbSoi5f",
        "outputId": "295212b4-2cac-4f67-a948-1bd963cb6ef1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'abuzar',\n",
              "  'father': 'irshad',\n",
              "  'roll_number': 18,\n",
              "  'address': 'larkana'},\n",
              " {'name': 'manzar',\n",
              "  'father': 'irshad',\n",
              "  'roll_number': 16,\n",
              "  'address': 'ratodero'},\n",
              " {'name': 'feroz',\n",
              "  'father': 'irshad',\n",
              "  'roll_number': 14,\n",
              "  'address': 'fatehpur'}]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "    \"models/gemini-1.5-pro\",\n",
        "    system_instruction=Instruction\n",
        ")\n",
        "chat=model.start_chat()\n",
        "get=chat.send_message(f\"tell me  the roll number 14 information: {student_info}\")\n",
        "print(get.text)"
      ],
      "metadata": {
        "id": "q9m_AenNqO64",
        "outputId": "5b1d1195-8347-40d7-dc6e-bd2ee6777c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{'name': 'feroz', 'father': 'irshad', 'roll_number': 14, 'address': 'fatehpur'}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Function_calling_config.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}