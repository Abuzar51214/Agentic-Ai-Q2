{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abuzar51214/Agentic-Ai-Q2/blob/main/Project_1_LangChain_Hello_World_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PZ2oNTIdsoU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8162e9d-4ccf-4196-9a2c-f5608945015b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain langchain-google-genai #SDK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "E7qpFO51tDF2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.0-flash-exp\",\n",
        "    api_key = GOOGLE_API_KEY,\n",
        "    temperature=0.6\n",
        ")"
      ],
      "metadata": {
        "id": "6BcWWWfnxcPp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Query=(\"what is difference between GenAI and Agentic AI?\")\n",
        "Response=llm.invoke(Query)"
      ],
      "metadata": {
        "id": "ogHwbt_lxqFc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Query:\", Query)\n",
        "print(\"Response:\", Response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o95jtzxs0TUG",
        "outputId": "7500474b-fa4d-45e2-90cf-5febe7e3c142"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: what is difference between GenAI and Agentic AI?\n",
            "Response: While both GenAI (Generative AI) and Agentic AI are hot topics in the field of artificial intelligence, they represent different capabilities and approaches. Here's a breakdown of their key differences:\n",
            "\n",
            "**GenAI (Generative AI)**\n",
            "\n",
            "* **Focus:** Creating new content, data, or artifacts.\n",
            "* **Core Function:** Generates outputs based on patterns learned from training data.\n",
            "* **Typical Tasks:**\n",
            "    * Text generation (writing articles, poems, code, etc.)\n",
            "    * Image generation (creating realistic or artistic images)\n",
            "    * Music composition\n",
            "    * Video generation\n",
            "    * 3D model creation\n",
            "    * Data synthesis\n",
            "* **Key Characteristics:**\n",
            "    * **Passive:** GenAI models typically don't act on their own. They respond to a prompt or input.\n",
            "    * **Single-Step Output:** Usually, they produce an output in a single step based on the provided input.\n",
            "    * **Lack of Planning/Reasoning:** They don't typically plan ahead, strategize, or reason about the best course of action to achieve a complex goal.\n",
            "    * **Examples:** DALL-E 2, Stable Diffusion, ChatGPT (in its basic text generation mode), Midjourney, Bard (in its basic text generation mode)\n",
            "\n",
            "**Agentic AI**\n",
            "\n",
            "* **Focus:** Autonomous agents that can perceive their environment, reason, plan, and act to achieve goals.\n",
            "* **Core Function:** Combines perception, reasoning, planning, and action to solve problems and interact with the world.\n",
            "* **Typical Tasks:**\n",
            "    * Complex problem-solving\n",
            "    * Task automation\n",
            "    * Decision-making\n",
            "    * Interaction with external systems and tools\n",
            "    * Learning and adapting to changing environments\n",
            "* **Key Characteristics:**\n",
            "    * **Active:** Agentic AI models can initiate actions and interact with their environment.\n",
            "    * **Multi-Step Output:** They often work through a series of steps, including planning, execution, and evaluation.\n",
            "    * **Reasoning and Planning:** They can reason about goals, devise plans, and adapt their strategies based on feedback.\n",
            "    * **Autonomous:** They can operate with a degree of autonomy, often without constant human intervention.\n",
            "    * **Examples:** Auto-GPT, BabyAGI, Tool-using Language Models (e.g., those that can browse the web, use APIs, etc.)\n",
            "\n",
            "**Here's a table summarizing the key differences:**\n",
            "\n",
            "| Feature          | GenAI (Generative AI)           | Agentic AI                     |\n",
            "|-------------------|-----------------------------------|---------------------------------|\n",
            "| **Primary Goal** | Content creation                | Autonomous action and problem-solving |\n",
            "| **Core Function**| Generates outputs from patterns   | Perceives, reasons, plans, acts  |\n",
            "| **Activity**      | Passive (responds to input)      | Active (initiates action)       |\n",
            "| **Output**        | Single-step, direct output      | Multi-step, iterative process    |\n",
            "| **Reasoning**     | Limited or absent                | Strong reasoning and planning   |\n",
            "| **Autonomy**      | Low                            | High                             |\n",
            "| **Interaction**  | Limited interaction with the world| Interacts with environment and tools |\n",
            "| **Examples**     | DALL-E 2, Stable Diffusion, ChatGPT (basic mode) | Auto-GPT, BabyAGI, Tool-using LLMs|\n",
            "\n",
            "**Relationship and Overlap:**\n",
            "\n",
            "* **Agentic AI often leverages GenAI:** Agentic AI systems often use GenAI models as a component. For instance, they might use a language model to generate text for a report, or an image generation model to create visualizations.\n",
            "* **GenAI can be a building block:** GenAI models provide the ability to generate text, images, and other forms of data, which can be essential for agentic AI systems to interact with the world.\n",
            "* **The line is blurring:** The field is rapidly evolving, and the distinction between GenAI and Agentic AI is becoming less clear-cut. Some models are incorporating elements of both.\n",
            "\n",
            "**In Simple Terms:**\n",
            "\n",
            "* **GenAI:** Think of it as a creative tool that can generate new things based on what it's learned. It's like a highly skilled artist or writer, but it needs to be given a prompt.\n",
            "* **Agentic AI:** Think of it as an intelligent robot that can understand its surroundings, make decisions, and carry out tasks to achieve a goal. It's like a highly capable assistant or problem-solver, capable of acting on its own.\n",
            "\n",
            "**In Conclusion:**\n",
            "\n",
            "GenAI is focused on creating new content, while Agentic AI is focused on creating autonomous systems that can achieve goals. Agentic AI often uses GenAI as a component, but it goes beyond simply generating outputs by adding reasoning, planning, and action capabilities. Understanding this distinction is crucial for navigating the rapidly evolving landscape of artificial intelligence.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_query=input(\"User Question: \")  # solve in while loop\n",
        "  if user_query.lower()==\"exit\":\n",
        "    print(\"Nice to meet\")\n",
        "    break\n",
        "  response=llm.invoke(user_query)\n",
        "  print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgt-xuMb1PPe",
        "outputId": "92abec7d-dd59-4068-de6d-cf12161474ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Question: what is langchain tell in briefly\n",
            "LangChain is a framework designed to make it easier to build applications powered by large language models (LLMs). Think of it as a toolkit that provides building blocks and pre-built components to help you:\n",
            "\n",
            "* **Connect to LLMs:** It offers a standardized way to interact with various LLMs like OpenAI's GPT models, Google's PaLM, and many others.\n",
            "* **Chain LLM Calls:** It allows you to create sequences of actions involving LLMs, like taking user input, processing it with one LLM, then using the output with another LLM or a tool.\n",
            "* **Integrate with External Data and Tools:** It enables you to connect your LLM applications to external sources like databases, APIs, and search engines.\n",
            "* **Manage Memory and Context:** It helps maintain context across multiple interactions with an LLM, allowing for more coherent and conversational applications.\n",
            "* **Build Complex Applications:** It provides abstractions and patterns to build sophisticated applications like chatbots, question-answering systems, and document summarizers.\n",
            "\n",
            "**In short, LangChain helps developers orchestrate and extend the capabilities of LLMs, making it easier to build powerful and practical AI-powered applications.** It handles a lot of the complexity involved in working with LLMs, letting you focus on the logic of your application.\n",
            "\n",
            "User Question: exit\n",
            "Nice to meet\n"
          ]
        }
      ]
    }
  ]
}