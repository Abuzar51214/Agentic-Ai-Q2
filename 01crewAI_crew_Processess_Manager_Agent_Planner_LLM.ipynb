{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abuzar51214/Agentic-Ai-Q2/blob/main/01crewAI_crew_Processess_Manager_Agent_Planner_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iReponSNE-6K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4KkKR07tGLmF",
        "outputId": "71d64ace-9916-44ea-cf68-833f7b930437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m252.1/252.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m548.5/548.5 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m33.2/33.2 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\n",
            "google-genai 1.4.0 requires httpx<1.0.0dev,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq crewai crewai-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeA509hTGj3P"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQbxNzRqJJLS",
        "outputId": "1f972e6a-ceff-4cb1-ee2d-4f6354ddcc8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:31:05][ğŸŒŠ FLOW CREATED: 'MYFLOW']: 2025-03-10 08:31:05.443236\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:31:05][ğŸ¤– FLOW STARTED: 'MYFLOW', F8CC073B-C949-4A07-92D1-A3A015375203]: 2025-03-10 08:31:05.443999\u001b[00m\n",
            "\u001b[1m\u001b[35m Flow started with ID: f8cc073b-c949-4a07-92d1-a3a015375203\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:31:05][ğŸ¤– FLOW METHOD STARTED: 'FUNCTION1']: 2025-03-10 08:31:05.444418\u001b[00m\n",
            "step1\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:31:05][ğŸ‘ FLOW METHOD FINISHED: 'FUNCTION1']: 2025-03-10 08:31:05.444534\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:31:05][ğŸ¤– FLOW METHOD STARTED: 'FUNCTION2']: 2025-03-10 08:31:05.444712\u001b[00m\n",
            "step2\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:31:05][ğŸ‘ FLOW METHOD FINISHED: 'FUNCTION2']: 2025-03-10 08:31:05.444779\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:31:05][ğŸ‘ FLOW FINISHED: 'MYFLOW', F8CC073B-C949-4A07-92D1-A3A015375203]: 2025-03-10 08:31:05.444905\u001b[00m\n"
          ]
        }
      ],
      "source": [
        "from crewai.flow.flow import Flow,start,listen\n",
        "\n",
        "class Myflow(Flow):\n",
        "  @start()\n",
        "  def function1(self):\n",
        "    print(\"step1\")\n",
        "  @listen(function1)\n",
        "  def function2(self):\n",
        "     print(\"step2\")\n",
        "\n",
        "\n",
        "obj=Myflow()\n",
        "obj.kickoff()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZN7dK7uKo02"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "Gemini_API=userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "rIcfv6S0JtvH",
        "outputId": "ecb0ea29-8ed4-4115-dfbb-98bc801b737d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:31:09][ğŸ¤– LLM CALL STARTED]: 2025-03-10 08:31:09.472194\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:31:10][âœ… LLM CALL COMPLETED]: 2025-03-10 08:31:10.770190\u001b[00m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The capital of Iran is **Tehran**.\\n'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from crewai import LLM\n",
        "llm1=LLM(\n",
        "    model=\"gemini/gemini-2.0-flash\",\n",
        "\n",
        "    )\n",
        "llm1.call(\"what is capital of Iran?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3NStzBYQCPe"
      },
      "outputs": [],
      "source": [
        "google_embedder={\n",
        "        \"provider\":\"google\",\n",
        "        \"config\":{\n",
        "            \"model\":\"models/text-embedding-004\",\n",
        "            \"api_key\":userdata.get(\"GEMINI_API_KEY\")\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "Om5WQ7zlMLe6",
        "outputId": "6f83be21-3925-44f5-f898-04f62f763554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:58:34][ğŸš€ CREW 'CREW' STARTED, 4F3E1095-A86D-4F4C-A18C-094EF3A89FC7]: 2025-03-10 08:58:34.488989\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:58:34][ğŸ“‹ TASK STARTED: ANSWER THE FOLLOWING QUESTION ABOUT THE USER: WHAT CITY DOES MUHAMMAD QASIM LIVE IN AND HOW OLD HE IS?]: 2025-03-10 08:58:34.500941\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:58:38][ğŸ¤– AGENT 'ABOUT USER' STARTED TASK]: 2025-03-10 08:58:38.192766\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mAnswer the following question about the user: what city does Muhammad Qasim live in and how old he is?\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:58:38][ğŸ¤– LLM CALL STARTED]: 2025-03-10 08:58:38.193020\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:58:39][âœ… LLM CALL COMPLETED]: 2025-03-10 08:58:39.654598\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Muhammad Qasim lives in Karachi and he is 30 years old.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:58:47][âœ… AGENT 'ABOUT USER' COMPLETED TASK]: 2025-03-10 08:58:47.385916\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:58:47][âœ… TASK COMPLETED: ANSWER THE FOLLOWING QUESTION ABOUT THE USER: WHAT CITY DOES MUHAMMAD QASIM LIVE IN AND HOW OLD HE IS?]: 2025-03-10 08:58:47.386312\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-10 08:58:47][âœ… CREW 'CREW' COMPLETED, 4F3E1095-A86D-4F4C-A18C-094EF3A89FC7]: 2025-03-10 08:58:47.394731\u001b[00m\n"
          ]
        }
      ],
      "source": [
        "from crewai import Agent, Task, Crew, Process\n",
        "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
        "\n",
        "#create a knowledge Source\n",
        "content=\"User name is Muhammad Qasim, He is 30 years old and live in karachi\"\n",
        "string_source=StringKnowledgeSource(\n",
        "    content=content\n",
        ")\n",
        "\n",
        "#create An agent with knowledge source\n",
        "agent=Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preference \"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "task=Task(\n",
        "    description=\"Answer the following question about the user: {question}\",\n",
        "    expected_output=\"An Answer to the question\",\n",
        "    agent=agent\n",
        ")\n",
        "crew=Crew(\n",
        "    memory=True,\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    verbose=True,\n",
        "    process=Process.sequential,\n",
        "    knowledge_sources=[string_source],     #enable knowledge by adding sources here. You can also add more sources list.\n",
        "    embedder=google_embedder\n",
        ")\n",
        "result=crew.kickoff(inputs={\"question\":\"what city does Muhammad Qasim live in and how old he is?\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedder={\n",
        "    \"provider\":\"google\",\n",
        "    \"config\":{\n",
        "        \"model\":\"models/text-embedding-004\",\n",
        "        \"api_key\":userdata.get(\"GEMINI_API_KEY\")\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "CWul_Kw9w7ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CREWAI_STORAGE_DIR\"]='/my_crew1'"
      ],
      "metadata": {
        "id": "5zu0cJSkxVkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM\n",
        "llm1=LLM(\n",
        "    model=\"gemini/gemini-2.0-flash\"\n",
        ")"
      ],
      "metadata": {
        "id": "KadCetECxlSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew, Process\n",
        "from crewai.memory import LongTermMemory, ShortTermMemory, EntityMemory\n",
        "from crewai.memory.storage import LTMSQLiteStorage, RAGStorage\n",
        "from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n",
        "from crewai.memory.storage.rag_storage import RAGStorage\n",
        "from typing import List, Optional\n",
        "\n",
        "#create Agent with knowledge store\n",
        "\n",
        "agent=Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You Know everything about the user\",\n",
        "    backstory=\"You are a master at understanding people and their prefferences.\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm1\n",
        "\n",
        ")\n",
        "\n",
        "task=Task(\n",
        "    description=\"Answer the following question about the user: {question}\",\n",
        "    expected_output=\"An Answer to the question\",\n",
        "    agent=agent\n",
        ")\n",
        "\n",
        "crew=Crew(\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    process=Process.sequential,\n",
        "    memory=True,\n",
        "    #LongTerm memory for presistent storage accross sessions\n",
        "    long_term_memory=LongTermMemory(\n",
        "        storage=LTMSQLiteStorage(\n",
        "            db_path=\"./my_crew2/long_term_memory.db\"\n",
        "        )\n",
        "    ),\n",
        "    #short term memory for current context using RAG\n",
        "    short_term_memory=ShortTermMemory(\n",
        "        storage=RAGStorage(\n",
        "            embedder_config=embedder,\n",
        "            type=\"short_term\",\n",
        "            path=\"./my_crew2/short_term1/\"\n",
        "        )\n",
        "    ),\n",
        "    #Entity memory for tracking key inforamtation about entities\n",
        "    entity_memory=EntityMemory(\n",
        "        storage=RAGStorage(\n",
        "            embedder_config=embedder,\n",
        "            type=\"short_term\",\n",
        "            path=\"./my_crew2/entity1/\"\n",
        "        )\n",
        "    ),\n",
        "    verbose=True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "LUE4HOF-xz3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Integrating Mem0 for enhanced user Memory"
      ],
      "metadata": {
        "id": "qquT6doX2kYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from crewai import Crew, Process\n",
        "from mem0 import MemoryClient\n",
        "\n",
        "# Set environment variables for Mem0\n",
        "os.environ[\"MEM0_API_KEY\"] = userdata.get('MEM0_API_KEY')\n",
        "\n",
        "# Step 1: Record preferences based on past conversation or user input\n",
        "client = MemoryClient()\n",
        "# messages = [\n",
        "#     {\"role\": \"user\", \"content\": \"Hi there! I'm planning a vacation and could use some advice.\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to help with your vacation planning. What kind of destination do you prefer?\"},\n",
        "#     {\"role\": \"user\", \"content\": \"I am more of a beach person than a mountain person.\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"That's interesting. Do you like hotels or Airbnb?\"},\n",
        "#     {\"role\": \"user\", \"content\": \"I like Airbnb more.\"},\n",
        "# ]\n",
        "# client.add(messages, user_id=\"john\")\n",
        "\n",
        "# Step 2: Create a Crew with User Memory\n",
        "\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm1,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    process = Process.sequential,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    memory_config={\n",
        "        \"provider\": \"mem0\",\n",
        "        \"config\": {\"user_id\": \"john\"},\n",
        "    },\n",
        ")\n",
        "\n",
        "crew.kickoff(inputs={\"question\": \"What is your favorite vacation destination?\"})"
      ],
      "metadata": {
        "id": "_XPS3xw_7WT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tool"
      ],
      "metadata": {
        "id": "Z64_i0a59VDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq 'crewai[tools]'"
      ],
      "metadata": {
        "id": "Ae5Td7rl7DBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"SERPER_API_KEY\"]=userdata.get(\"SERPER_API_KEY\")"
      ],
      "metadata": {
        "id": "lPb16w2B9i_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedder={\n",
        "    \"provider\":\"google\",\n",
        "    \"config\":{\n",
        "        \"model\":\"model/text-embedding-004\",\n",
        "        \"api_key\":userdata.get(\"GEMINI_API_KEY\")\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "WC38bsYL9q_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -Uq langchain-google-genai"
      ],
      "metadata": {
        "id": "iBgOe7sYYQLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm1=LLM(model=\"gemini/gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "BVaBaAkuyj_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "# Importing crewAI tools\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")\n",
        "\n",
        "# Set up API keys\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY') # serper.dev API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY_S')\n",
        "\n",
        "# Instantiate tools\n",
        "docs_tool = DirectoryReadTool(directory='./blog-posts')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()\n",
        "\n",
        "# Create agents\n",
        "researcher = Agent(\n",
        "    role='Market Research Analyst',\n",
        "    goal='Provide up-to-date market analysis of the AI industry',\n",
        "    backstory='An expert analyst with a keen eye for market trends.',\n",
        "    tools=[search_tool, web_rag_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "    role='Content Writer',\n",
        "    goal='Craft engaging blog posts about the AI industry',\n",
        "    backstory='A skilled writer with a passion for technology.',\n",
        "    tools=[docs_tool, file_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "# Define tasks\n",
        "research = Task(\n",
        "    description='Research the latest trends in the AI industry and provide a summary.',\n",
        "    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',\n",
        "    agent=researcher\n",
        ")\n",
        "\n",
        "write = Task(\n",
        "    description='Write an engaging blog post about the AI industry, based on the research analystâ€™s summary. Draw inspiration from the latest blog posts in the directory.',\n",
        "    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',\n",
        "    agent=writer,\n",
        "    output_file='blog-posts/new_post.md'  # The final blog post will be saved here\n",
        ")\n",
        "\n",
        "# Assemble a crew with planning enabled\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer],\n",
        "    tasks=[research, write],\n",
        "    verbose=True,\n",
        "    planning=True,  # Enable planning feature\n",
        "    planning_llm=llm1\n",
        ")\n",
        "\n",
        "# Execute tasks\n",
        "crew.kickoff()"
      ],
      "metadata": {
        "id": "_PNZVpcE-ITS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "def display_markdown_file(file_path):\n",
        "  with open(file_path, 'r') as f:\n",
        "    content=f.read()\n",
        "  display(Markdown(content))\n",
        "display_markdown_file('blog-posts/new_post.md')"
      ],
      "metadata": {
        "id": "Gs0Og6DQ2_2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Own tools\n"
      ],
      "metadata": {
        "id": "bj8joQp13wgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai.tools import BaseTool\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import type\n",
        "\n",
        "class MyToolInput(BaseModel):\n",
        "  \"\"\"Input schema for MyCustomTool.\"\"\"\n",
        "  student_name:str=Field(..., description=\"Student name\")\n",
        "  student_roll_no:int=Field(..., description=\"Student id\")\n",
        "class PiaicStudentCard(BaseTool):\n",
        "  name:str= \"Piaic student card\"\n",
        "  description:str=\"this function will create student card\"\n",
        "  args_schema: Type[BaseModel]=MyToolInput\n",
        "\n",
        "  def _run(self, student_name:str, student_roll_no:int)-> str:\n",
        "    #Logic is here\n",
        "    return f\"\"\"PIAIC Student Card\n",
        "    student name: {student_name}\n",
        "    student roll no: {student_roll_no}\n",
        "    \"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "zXFERleN3shG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai.tools import tools\n",
        "@tool(\"PIAIC fee update\")\n",
        "def my_tool(roll_no: int)-> int:\n",
        "  \"\"\"This function search piaic student fee update, it will required roll no of PIAIC student\"\"\"\n",
        "  #Database\n",
        "  data={\n",
        "      100:\"paid\",\n",
        "      200:\"unpaid\"\n",
        "  }\n",
        "  status=data.get(roll_no)\n",
        "  if status:\n",
        "    return {\"status\":status}\n",
        "  else:\n",
        "    return \"student not found\""
      ],
      "metadata": {
        "id": "C95YcT2y7SGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "card = PiaicStudentCard()\n",
        "\n",
        "\n",
        "piaic_manager = Agent(\n",
        "    role=\"PIAIC manager\",\n",
        "    goal = \"Manage all quries regarding PIAIC and you will use only relevant tools for student query\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    tools=[card, my_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "piaic_card_creator = Task(\n",
        "    description=\"you will be responsible for all PIAIC relevant operations, student query '{query}' you must be know how to answer his question based on final context\",\n",
        "    expected_output=\"final query answer only\",\n",
        "    agent=piaic_manager\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[piaic_manager],\n",
        "    tasks=[piaic_card_creator],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = crew.kickoff(inputs={\n",
        "    \"query\":\"I'm PIAIC student my name is Muhammad Qasim and my roll number is 100, can you create my student card.\"\n",
        "})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "G5y26sAb8hhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=crew.kickoff(inputs={\"query\":\"I am student of PIAIC my roll no is 100 can you share my fee update?\"})"
      ],
      "metadata": {
        "id": "54MeIVYZwpRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Process"
      ],
      "metadata": {
        "id": "HHKgX2IFxlaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "# Importing crewAI tools\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate tools\n",
        "docs_tool = DirectoryReadTool(directory='./blog-posts2')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()\n",
        "\n",
        "# Define your agents\n",
        "researcher = Agent(\n",
        "    role=\"Researcher\",\n",
        "    goal=\"Conduct thorough research and analysis on AI and AI agents\",\n",
        "    backstory=\"You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.\",\n",
        "    allow_delegation=False,\n",
        "    tools=[search_tool,web_rag_tool],\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "    role=\"Senior Writer\",\n",
        "    goal=\"Create compelling content about AI and AI agents\",\n",
        "    backstory=\"You're a senior writer, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently writing content for a new client.\",\n",
        "    allow_delegation=False,\n",
        "    tools=[docs_tool,file_tool],\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "# Define your task\n",
        "task = Task(\n",
        "    description=\"Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.\",\n",
        "    expected_output=\"5 bullet points, each with a paragraph and accompanying notes.\",\n",
        ")\n",
        "\n",
        "# Define the manager agent\n",
        "manager = Agent(\n",
        "    role=\"Project Manager\",\n",
        "    goal=\"Efficiently manage the crew and ensure high-quality task completion\",\n",
        "    backstory=\"You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.\",\n",
        "    allow_delegation=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "# Instantiate your crew with a custom manager\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer],\n",
        "    tasks=[task],\n",
        "    manager_agent=manager,\n",
        "    function_calling_llm=llm1,\n",
        "    process=Process.hierarchical,\n",
        "    verbose=True\n",
        "\n",
        ")\n",
        "\n",
        "# Start the crew's work\n",
        "result = crew.kickoff()\n",
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(result.raw)\n",
        ""
      ],
      "metadata": {
        "id": "M9tEyGT3xoUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Advance Tool"
      ],
      "metadata": {
        "id": "88Yd_hbDuQDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "class TeacherAssignmentOutPut(BaseModel):\n",
        "    score:str=Field(..., description=\"student assignment score\")\n",
        "    feedback:str=Field(..., description=\"teacher feedback\")\n",
        "    question:str=Field(..., description=\"question\")\n",
        "    answer:str=Field(..., description=\"python code for markdown format\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fVcAzuRNuT5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent\n",
        "from crewai_tools import CodeInterpreterTool\n",
        "from crewai import Task, Crew, Process\n",
        "\n",
        "teacher=Agent(\n",
        "    role=\"AI Teacher\",\n",
        "    goal=\"You are an Agentic AI Teacher you have to check python assignement code submission\",\n",
        "    backstory=\"you have to check python assignement code submission\",\n",
        "    tools=[CodeInterpreterTool()],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "assignment_checker=Task(\n",
        "    description=\"you are Agentic AI AI teacher, you have to check python assignment code submission. question: '''{question}''' student solution: '''{solution}''' \",\n",
        "    expected_output=\"final code running assign number between 1-10\",\n",
        "    output_pydantic=TeacherAssignmentOutPut,\n",
        "    agent=teacher\n",
        ")\n",
        "\n",
        "crew=Crew(\n",
        "    agents=[teacher],\n",
        "    tasks=[assignment_checker],\n",
        "    process=Process.sequential,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "question=\"create function add two numbers\"\n",
        "\n",
        "solution=\"\"\"\n",
        "def add_two_num(num1, num2):\n",
        "  return num1+num2\n",
        "\"\"\"\n",
        "result=crew.kickoff(inputs={\n",
        "    \"question\":question,\n",
        "    \"solution\":solution\n",
        "                            })\n",
        "print(result)"
      ],
      "metadata": {
        "id": "q8GvftLkqkeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.dict()"
      ],
      "metadata": {
        "id": "4vHTXJOSxWbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in result.to_dict().items():\n",
        "  print(str(\"*\"*10) + str(k) + str(\"*\"*10))\n",
        "  display(v)"
      ],
      "metadata": {
        "id": "mGeQbIbWxZ9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CuLq5FR6e7pD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4CTpz2zzB9N2cav5pvTIm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}